{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SWxvrqY8Yx9Y",
        "outputId": "53e0f09f-4142-46f9-d10c-75a6e899c8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: blobfile in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.21.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile) (2.2.3)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile) (4.9.4)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/')\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "from safetensors.torch import save_file, safe_open\n",
        "\n",
        "! pip install transformers -U\n",
        "! pip install tiktoken blobfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0-r8Qd_eYEA"
      },
      "source": [
        "## Get LLAMA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4nIUgQBNXi1"
      },
      "source": [
        "#### Go to this link and follow the steps [https://huggingface.co/docs/transformers/en/model_doc/llama](https://huggingface.co/docs/transformers/en/model_doc/llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zEgiVlLMPvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963b5682-ea38-4c6b-9399-0e82846fe070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checklist.chk  consolidated.00.pth  params.json  tokenizer.model\n",
            "2024-10-26 06:41:08.092054: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-10-26 06:41:08.113896: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-26 06:41:08.141165: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-26 06:41:08.147956: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-26 06:41:08.167143: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-26 06:41:09.496131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Converting the tokenizer.\n",
            "Saving a LlamaTokenizerFast to ./llama_3.2-3B-huggingface.\n",
            "Converting the model.\n",
            "Fetching all parameters from the checkpoint at ./Llama3.2-3B.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/convert_llama_weights_to_hf.py:231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded = torch.load(os.path.join(input_base_path, \"consolidated.00.pth\"), map_location=\"cpu\")\n",
            "Loading the checkpoint in a Llama model.\n",
            "Loading checkpoint shards: 100% 29/29 [00:06<00:00,  4.74it/s]\n",
            "Saving in the Transformers format.\n",
            "Saving to disk.\n"
          ]
        }
      ],
      "source": [
        "# ! ls '/content/drive/MyDrive/llama_3.2-3B-huggingface'\n",
        "# ! cp -r '/content/drive/MyDrive/llama_3.2-3B-huggingface' './llama_3.2-3B-huggingface'\n",
        "\n",
        "! ls '/content/drive/MyDrive/Llama3.2-3B'\n",
        "! cp -r '/content/drive/MyDrive/Llama3.2-3B' './Llama3.2-3B'\n",
        "\n",
        "! python /usr/local/lib/python3.10/dist-packages/transformers/models/llama/convert_llama_weights_to_hf.py --input_dir ./Llama3.2-3B --model_size 3B --llama_version 3.2 --output_dir ./llama_3.2-3B-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P44NDUEQedEs"
      },
      "source": [
        "### Inference Using downloaded model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7BzOwXQPt1z"
      },
      "outputs": [],
      "source": [
        "# ! cp -r '/content/drive/MyDrive/llama_3.2-3B-huggingface' './llama_3.2-3B-huggingface'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e9c9d226f3ed4e0bbca5d7ffda272729",
            "a96ba9ccc7fc4df2822edf29f97dfd93",
            "783d758e587f4173b481b579556a0d79",
            "48e04f100d204c3fa63cef6dab102532",
            "db501b731109441d845adf617becaa94",
            "2a48dfe02a494fc68b6e464f51e61f1a",
            "c4a789ee7b14460499baf8d05678a04e",
            "5b363ad02b7c40269083155076d7e5d5",
            "8be81f1627734ba987721d7d67358a2d",
            "c54f054e1b07467d9883527ba8df001e",
            "7aa527e235014890b499f3de805d0b2d"
          ]
        },
        "id": "UNwMV3g6gm67",
        "outputId": "2ad01a5d-b9b9-4b91-8fa9-9d3a07c99b1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c9d226f3ed4e0bbca5d7ffda272729"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "def load_model(model_id):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "  return tokenizer, model\n",
        "\n",
        "def generate_text(tokenizer, model, prompt, max_length=100):\n",
        "  input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "  output = model.generate(input_ids, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
        "  generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  return generated_text\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer, model = load_model('./llama_3.2-3B-huggingface')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "aB2i3a7nhF3S",
        "outputId": "79e9ab32-04a6-4f89-a140-fea2f5c77c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How much is 6593 Orchard Place, Burnaby, Canada? Answer: The cost for 6593 Orchard Place, Burnaby, Canada is $1,999,000 CAD. This price is based on current listings on Real Estate Central. The price may be out of date. To find current prices, go to Real Estate Central. Prices of homes have fallen in Burnaby by 16% this year, with 6593 Orchard Place, Burnaby, Canada being listed 6 days ago. By this we mean in the past 90 days. The 4 bed, 4 bath, 2,100 square foot home sitting on a 0.08 acre lot has been on Real Estate Central for 6 days.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Generate text\n",
        "prompt = \"How much is 6593 Orchard Place, Burnaby, Canada? Answer:\"\n",
        "rst = generate_text(tokenizer, model, prompt, max_length=150)\n",
        "rst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHB53YoaWC93"
      },
      "source": [
        "### Rechunk the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSHyeuNhdJHH",
        "outputId": "656dd423-3c19-410a-af21-23d5343a0ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checklist.chk  consolidated.00.pth  params.json  tokenizer.model\n",
            "2024-10-26 07:32:23.694335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-26 07:32:23.716719: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-26 07:32:23.723467: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-26 07:32:24.914703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Converting the tokenizer.\n",
            "Saving a LlamaTokenizerFast to ./llama_3.2-3B-huggingface.\n",
            "Converting the model.\n",
            "Fetching all parameters from the checkpoint at ./Llama3.2-3B.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/convert_llama_weights_to_hf.py:231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded = torch.load(os.path.join(input_base_path, \"consolidated.00.pth\"), map_location=\"cpu\")\n",
            "Loading the checkpoint in a Llama model.\n",
            "Loading checkpoint shards: 100% 29/29 [00:06<00:00,  4.64it/s]\n",
            "Saving in the Transformers format.\n",
            "Saving to disk.\n"
          ]
        }
      ],
      "source": [
        "! ls '/content/drive/MyDrive/Llama3.2-3B'\n",
        "! cp -r '/content/drive/MyDrive/Llama3.2-3B' './Llama3.2-3B'\n",
        "\n",
        "! python /usr/local/lib/python3.10/dist-packages/transformers/models/llama/convert_llama_weights_to_hf.py --input_dir ./Llama3.2-3B --model_size 3B --llama_version 3.2 --output_dir ./llama_3.2-3B-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_safetensors(root_path, safetensor_file, embed_layer, shardnum):\n",
        "\n",
        "  embed_list = []\n",
        "\n",
        "  with safe_open(safetensor_file, framework=\"pt\", device=\"cpu\") as f:\n",
        "    x = f.get_tensor(embed_layer)\n",
        "    splits = torch.chunk(x, shardnum)\n",
        "\n",
        "    for i, split in enumerate(splits):\n",
        "      tmp_embed_name = f\"{embed_layer}-{str(i).zfill(2)}.safetensors\"\n",
        "      save_file({embed_layer: split}, os.path.join(root_path, tmp_embed_name), metadata={'format': 'pt'})\n",
        "      embed_list.append(tmp_embed_name)\n",
        "\n",
        "  return embed_list\n",
        "\n",
        "def merge_safetensors(root_path, safetensor_files, output_file):\n",
        "    merged_data = {}\n",
        "    output_tensor = []\n",
        "\n",
        "    for safetensor_file in safetensor_files:\n",
        "      with safe_open(os.path.join(root_path, safetensor_file), framework=\"pt\", device=\"cpu\") as f:\n",
        "        for key in f.keys():\n",
        "          output_tensor.append(f.get_tensor(key))\n",
        "\n",
        "    merged_data[key] = torch.cat(output_tensor, dim=0)\n",
        "    save_file(merged_data, os.path.join(root_path, output_file), metadata={'format': 'pt'})\n",
        "    return output_file"
      ],
      "metadata": {
        "id": "NdGDbWvilLXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = './llama_3.2-3B-huggingface/'\n",
        "\n",
        "safetensor_files = [f\"{root_path}model-00001-of-00002.safetensors\", f\"{root_path}model-00002-of-00002.safetensors\"]\n",
        "overall_count, index_names = 0, []\n",
        "embed_layer = 'embed_tokens'\n",
        "\n",
        "# Open the safetensors file and load the tensors\n",
        "for safetensor_file in safetensor_files:\n",
        "  with safe_open(safetensor_file, framework=\"pt\", device=\"cpu\") as f:\n",
        "    for key in f.keys():\n",
        "      if embed_layer in key:\n",
        "        split_file_names = split_safetensors(root_path, safetensor_file, key, 10)\n",
        "        merge_safetensors(root_path, split_file_names, f\"{embed_layer}.safetensors\")\n",
        "        index_names.append(f\"{embed_layer}.safetensors\")\n",
        "      else:\n",
        "        save_file({key: f.get_tensor(key)}, os.path.join(root_path, f\"model-{str(overall_count).zfill(5)}-{key}.safetensors\"), metadata={'format': 'pt'})\n",
        "        index_names.append(f\"model-{str(overall_count).zfill(5)}-{key}.safetensors\")\n",
        "      overall_count += 1\n",
        "\n",
        "# Generate new index json\n",
        "indexs = {}\n",
        "for path in index_names:\n",
        "  with safe_open(os.path.join(root_path, path), framework=\"pt\", device=\"cpu\") as f:\n",
        "    for key in f.keys():\n",
        "      indexs[key] = path\n",
        "\n",
        "\n",
        "# Change new index JSON\n",
        "safetensor_file = \"./llama_3.2-3B-huggingface/model.safetensors.index.json\"\n",
        "with open(safetensor_file, 'r') as f:\n",
        "  index_tensors = json.load(f)\n",
        "  for k in index_tensors['weight_map']:\n",
        "    index_tensors['weight_map'][k] = indexs[k]\n",
        "\n",
        "with open(safetensor_file, 'w') as f:\n",
        "  json.dump(index_tensors, f)\n",
        "\n"
      ],
      "metadata": {
        "id": "l1O94rUZDlFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1BGRrCl5kpr"
      },
      "source": [
        "### Check if Same"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! rm ./llama_3.2-3B-huggingface/model-*-of-*.safetensors"
      ],
      "metadata": {
        "id": "i95xEkV6KdGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3a7c7de2df6d4b3989959df3bb28bd09",
            "772b5681ad5e41768e0d56e73a80601f",
            "513a1cbd9a7d4e3c86885551bd1804d0",
            "7bda8351e581495eb40780bed08b52b0",
            "4d873a3824ab429c9b9260577d251415",
            "f5c30b7533a54f7c9f9100edeb3fde15",
            "b48e37b7297d4972853ff4d66b56e728",
            "6cfbc7df60724c1ca1f61ea3dab7dc9e",
            "3d4365f6bc9a4e6da1f424e7e637941b",
            "8bf319736bff481a9cbe4eea8b571ba2",
            "4693169dea3d4a1898215c11c87fe1a8"
          ]
        },
        "id": "ZPKNwXAPEk3w",
        "outputId": "6c4c18c4-09f3-4fe1-f547-ace0ad61f273"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a7c7de2df6d4b3989959df3bb28bd09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/254 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load tokenizer and model\n",
        "# tokenizer, model = load_model(\"/content/drive/MyDrive/llama_3.2-3B-huggingface\")\n",
        "tokenizer_1, model_1 = load_model(\"./llama_3.2-3B-huggingface/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGtBxdgnyJ4M"
      },
      "outputs": [],
      "source": [
        "\n",
        "for (name, param), (name_2, param_2) in zip(model.named_parameters(), model_1.named_parameters()):\n",
        "  # print(name, (param == param_2).data.all().data)\n",
        "  if not (param == param_2).data.all().data:\n",
        "    print(name, param, param_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bKvOigZcgQLi",
        "outputId": "1e9464c9-fcbb-4f43-aa6c-2a3a8e7ea07f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How much is 6593 Orchard Place, Burnaby, Canada? Answer: The cost of 6593 Orchard Place, Burnaby, Canada is C$ 1,995,000.\\nHow much is 6593 Orchard Place, Burnaby, Canada?\\nThe price of 6593 Orchard Place, Burnaby, Canada is C$ 1,995,000.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# Generate text\n",
        "prompt = \"How much is 6593 Orchard Place, Burnaby, Canada? Answer:\"\n",
        "rst = generate_text(tokenizer_1, model_1, prompt, max_length=150)\n",
        "rst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "-Z5qIi_Vvn36",
        "outputId": "24ac2587-28fa-4eb5-8cb9-9495e8ac5c46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"How much is 6593 Orchard Place, Burnaby, Canada? Answer: The price is C$ 2,798,000 or per square meter 700 CAD.\\n6593 Orchard Place is a townhouse located in Burnaby, Canada. The price per square meter for this townhouse is C$ 700 CAD and is 6593 square meters (or 7069 square feet), on 6593 square meters of land.\\nIf you're the do-it-yourself type, you can save on the cost of a real estate agent by buying this property and doing the work yourself, or by hiring your own contractor. The cost of a real estate agent's commission in this case would be 2.75% of the purchase\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Generate text\n",
        "prompt = \"How much is 6593 Orchard Place, Burnaby, Canada? Answer:\"\n",
        "rst = generate_text(tokenizer, model, prompt, max_length=150)\n",
        "rst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKn2W2mo8dGD"
      },
      "source": [
        "### Git Push"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shardnum = 5\n",
        "\n",
        "shard_folders = [root_path.rstrip(\"/\") + f\"-shard{x}\" for x in range(shardnum)]\n",
        "for shard_folder in shard_folders:\n",
        "  if os.path.exists(shard_folder):\n",
        "    shutil.rmtree(shard_folder)\n",
        "  os.mkdir(shard_folder)\n",
        "\n",
        "files = os.listdir(root_path)\n",
        "files = sorted([x for x in files if not x.endswith(\".safetensors\")]) + sorted([x for x in files if x.endswith(\".safetensors\")])\n",
        "\n",
        "def split_list(lst, n_pieces):\n",
        "    # Calculate the approximate size of each piece\n",
        "    k, m = divmod(len(lst), n_pieces)\n",
        "    return [lst[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n_pieces)]\n",
        "\n",
        "pieces = split_list(files, shardnum)\n",
        "\n",
        "for piece in pieces:\n",
        "  for file in piece:\n",
        "    shutil.move(os.path.join(root_path, file), os.path.join(shard_folders[pieces.index(piece)], file))\n"
      ],
      "metadata": {
        "id": "WPiU9IhhJpE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J408raSArPJN",
        "outputId": "0f25f5a0-9fa2-4ce5-8ede-98514f6b66e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 0\n",
            "total 1.1G\n",
            "-rw-r--r-- 1 root root  50K Oct 26 07:32 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  301 Oct 26 07:32 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root  17M Oct 26 07:32 tokenizer.json\n",
            "-rw-r--r-- 1 root root  839 Oct 26 07:33 config.json\n",
            "-rw-r--r-- 1 root root  150 Oct 26 07:33 generation_config.json\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00001-model.layers.0.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00002-model.layers.0.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00003-model.layers.0.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00004-model.layers.0.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00005-model.layers.0.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00006-model.layers.0.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00007-model.layers.0.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00008-model.layers.0.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00009-model.layers.0.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00010-model.layers.1.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00011-model.layers.1.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00012-model.layers.1.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00013-model.layers.1.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00014-model.layers.1.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00015-model.layers.1.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00016-model.layers.1.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00017-model.layers.1.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00018-model.layers.1.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00019-model.layers.10.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00020-model.layers.10.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00021-model.layers.10.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00022-model.layers.10.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00023-model.layers.10.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00024-model.layers.10.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00025-model.layers.10.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00026-model.layers.10.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00027-model.layers.10.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00028-model.layers.11.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00029-model.layers.11.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00030-model.layers.11.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00031-model.layers.11.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00032-model.layers.11.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00033-model.layers.11.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00034-model.layers.11.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00035-model.layers.11.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00036-model.layers.11.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00037-model.layers.12.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00038-model.layers.12.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00039-model.layers.12.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00040-model.layers.12.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00041-model.layers.12.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00042-model.layers.12.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00043-model.layers.12.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00044-model.layers.12.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00045-model.layers.12.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00046-model.layers.13.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00047-model.layers.13.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00048-model.layers.13.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  27K Oct 26 08:00 model.safetensors.index.json\n",
            "total 1.2G\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00049-model.layers.13.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00050-model.layers.13.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00051-model.layers.13.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00052-model.layers.13.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00053-model.layers.13.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00054-model.layers.13.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00055-model.layers.14.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00056-model.layers.14.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00057-model.layers.14.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00058-model.layers.14.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00059-model.layers.14.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00060-model.layers.14.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00061-model.layers.14.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00062-model.layers.14.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00063-model.layers.14.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00064-model.layers.15.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00065-model.layers.15.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00066-model.layers.15.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00067-model.layers.15.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00068-model.layers.15.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00069-model.layers.15.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00070-model.layers.15.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00071-model.layers.15.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00072-model.layers.15.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00073-model.layers.16.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00074-model.layers.16.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00075-model.layers.16.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00076-model.layers.16.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00077-model.layers.16.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00078-model.layers.16.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00079-model.layers.16.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00080-model.layers.16.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00081-model.layers.16.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00082-model.layers.17.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00083-model.layers.17.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00084-model.layers.17.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00085-model.layers.17.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00086-model.layers.17.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00087-model.layers.17.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00088-model.layers.17.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00089-model.layers.17.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00090-model.layers.17.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00091-model.layers.18.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00092-model.layers.18.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00093-model.layers.18.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00094-model.layers.18.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00095-model.layers.18.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00096-model.layers.18.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00097-model.layers.18.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00098-model.layers.18.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00099-model.layers.18.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00100-model.layers.19.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00101-model.layers.19.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00102-model.layers.19.mlp.gate_proj.weight.safetensors\n",
            "total 1.2G\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00103-model.layers.19.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00104-model.layers.19.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00105-model.layers.19.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00106-model.layers.19.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00107-model.layers.19.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00108-model.layers.19.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00109-model.layers.2.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00110-model.layers.2.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00111-model.layers.2.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00112-model.layers.2.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00113-model.layers.2.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00114-model.layers.2.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00115-model.layers.2.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00116-model.layers.2.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00117-model.layers.2.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00118-model.layers.20.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00119-model.layers.20.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00120-model.layers.20.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00121-model.layers.20.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00122-model.layers.20.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00123-model.layers.20.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00124-model.layers.3.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00125-model.layers.3.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00126-model.layers.3.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00127-model.layers.3.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00128-model.layers.3.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00129-model.layers.3.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00130-model.layers.3.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00131-model.layers.3.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00132-model.layers.3.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00133-model.layers.4.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00134-model.layers.4.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00135-model.layers.4.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00136-model.layers.4.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00137-model.layers.4.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00138-model.layers.4.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00139-model.layers.4.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00140-model.layers.4.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00141-model.layers.4.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00142-model.layers.5.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00143-model.layers.5.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00144-model.layers.5.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00145-model.layers.5.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00146-model.layers.5.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00147-model.layers.5.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00148-model.layers.5.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00149-model.layers.5.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00150-model.layers.5.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00151-model.layers.6.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00152-model.layers.6.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00153-model.layers.6.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00154-model.layers.6.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00155-model.layers.6.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00156-model.layers.6.self_attn.k_proj.weight.safetensors\n",
            "total 1.2G\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00157-model.layers.6.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00158-model.layers.6.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00159-model.layers.6.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00160-model.layers.7.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00161-model.layers.7.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00162-model.layers.7.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00163-model.layers.7.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00164-model.layers.7.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00165-model.layers.7.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00166-model.layers.7.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00167-model.layers.7.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00168-model.layers.7.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00169-model.layers.8.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00170-model.layers.8.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00171-model.layers.8.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00172-model.layers.8.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00173-model.layers.8.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00174-model.layers.8.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00175-model.layers.8.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00176-model.layers.8.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00177-model.layers.8.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00178-model.layers.9.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00179-model.layers.9.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00180-model.layers.9.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00181-model.layers.9.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00182-model.layers.9.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00183-model.layers.9.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00184-model.layers.9.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00185-model.layers.9.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00186-model.layers.9.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00187-model.layers.20.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00188-model.layers.20.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00190-model.layers.21.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00189-model.layers.20.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00191-model.layers.21.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00192-model.layers.21.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00193-model.layers.21.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00194-model.layers.21.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00195-model.layers.21.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00196-model.layers.21.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00197-model.layers.21.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00198-model.layers.21.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00199-model.layers.22.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00200-model.layers.22.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00201-model.layers.22.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00202-model.layers.22.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00203-model.layers.22.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00204-model.layers.22.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00205-model.layers.22.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00206-model.layers.22.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00207-model.layers.22.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00208-model.layers.23.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00209-model.layers.23.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00210-model.layers.23.mlp.gate_proj.weight.safetensors\n",
            "total 1.6G\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-00.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-01.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-02.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-03.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-04.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-05.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-06.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-07.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-08.safetensors\n",
            "-rw-r--r-- 1 root root  76M Oct 26 08:00 model.embed_tokens.weight-09.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00211-model.layers.23.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00212-model.layers.23.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00213-model.layers.23.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00214-model.layers.23.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00215-model.layers.23.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00216-model.layers.23.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00217-model.layers.24.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00218-model.layers.24.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00219-model.layers.24.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00220-model.layers.24.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00221-model.layers.24.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00222-model.layers.24.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00223-model.layers.24.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00224-model.layers.24.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00225-model.layers.24.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00226-model.layers.25.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00227-model.layers.25.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00228-model.layers.25.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00229-model.layers.25.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00230-model.layers.25.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00231-model.layers.25.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00232-model.layers.25.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00233-model.layers.25.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00234-model.layers.25.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00235-model.layers.26.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00236-model.layers.26.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00237-model.layers.26.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00238-model.layers.26.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00239-model.layers.26.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00240-model.layers.26.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00241-model.layers.26.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00242-model.layers.26.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00243-model.layers.26.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00244-model.layers.27.input_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00245-model.layers.27.mlp.down_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00246-model.layers.27.mlp.gate_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  49M Oct 26 08:00 model-00247-model.layers.27.mlp.up_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00248-model.layers.27.post_attention_layernorm.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00249-model.layers.27.self_attn.k_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00250-model.layers.27.self_attn.o_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root  19M Oct 26 08:00 model-00251-model.layers.27.self_attn.q_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.1M Oct 26 08:00 model-00252-model.layers.27.self_attn.v_proj.weight.safetensors\n",
            "-rw-r--r-- 1 root root 6.2K Oct 26 08:00 model-00253-model.norm.weight.safetensors\n"
          ]
        }
      ],
      "source": [
        "! ls -lhtr ./llama_3.2-3B-huggingface\n",
        "\n",
        "! ls -lhtr ./llama_3.2-3B-huggingface-shard0\n",
        "! ls -lhtr ./llama_3.2-3B-huggingface-shard1\n",
        "! ls -lhtr ./llama_3.2-3B-huggingface-shard2\n",
        "! ls -lhtr ./llama_3.2-3B-huggingface-shard3\n",
        "! ls -lhtr ./llama_3.2-3B-huggingface-shard4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mv ./llama_3.2-3B-huggingface-shard0 /content/drive/MyDrive/\n",
        "! mv ./llama_3.2-3B-huggingface-shard1 /content/drive/MyDrive/\n",
        "! mv ./llama_3.2-3B-huggingface-shard2 /content/drive/MyDrive/\n",
        "! mv ./llama_3.2-3B-huggingface-shard3 /content/drive/MyDrive/\n",
        "! mv ./llama_3.2-3B-huggingface-shard4 /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "SkdrhtZC6f7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "126iEwoyBXL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a8653e-ebf7-4bbd-c768-7a20ff2f2dd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12822, 3072]), torch.Size([12826, 3072]))"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "splits[9].shape, splits[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls ./llama_3.2-3B-huggingface-shard0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrhHppolXenO",
        "outputId": "da9d4a91-9839-41f0-a0a0-a8184db2da85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\n",
            "generation_config.json\n",
            "model-00000-model.embed_tokens.weight.safetensors\n",
            "model-00001-model.layers.0.input_layernorm.weight.safetensors\n",
            "model-00002-model.layers.0.mlp.down_proj.weight.safetensors\n",
            "model-00003-model.layers.0.mlp.gate_proj.weight.safetensors\n",
            "model-00004-model.layers.0.mlp.up_proj.weight.safetensors\n",
            "model-00005-model.layers.0.post_attention_layernorm.weight.safetensors\n",
            "model-00006-model.layers.0.self_attn.k_proj.weight.safetensors\n",
            "model-00007-model.layers.0.self_attn.o_proj.weight.safetensors\n",
            "model-00008-model.layers.0.self_attn.q_proj.weight.safetensors\n",
            "model-00009-model.layers.0.self_attn.v_proj.weight.safetensors\n",
            "model-00010-model.layers.1.input_layernorm.weight.safetensors\n",
            "model-00011-model.layers.1.mlp.down_proj.weight.safetensors\n",
            "model-00012-model.layers.1.mlp.gate_proj.weight.safetensors\n",
            "model-00013-model.layers.1.mlp.up_proj.weight.safetensors\n",
            "model-00014-model.layers.1.post_attention_layernorm.weight.safetensors\n",
            "model-00015-model.layers.1.self_attn.k_proj.weight.safetensors\n",
            "model-00016-model.layers.1.self_attn.o_proj.weight.safetensors\n",
            "model-00017-model.layers.1.self_attn.q_proj.weight.safetensors\n",
            "model-00018-model.layers.1.self_attn.v_proj.weight.safetensors\n",
            "model-00019-model.layers.10.input_layernorm.weight.safetensors\n",
            "model-00020-model.layers.10.mlp.down_proj.weight.safetensors\n",
            "model-00021-model.layers.10.mlp.gate_proj.weight.safetensors\n",
            "model-00022-model.layers.10.mlp.up_proj.weight.safetensors\n",
            "model-00023-model.layers.10.post_attention_layernorm.weight.safetensors\n",
            "model-00024-model.layers.10.self_attn.k_proj.weight.safetensors\n",
            "model-00025-model.layers.10.self_attn.o_proj.weight.safetensors\n",
            "model-00026-model.layers.10.self_attn.q_proj.weight.safetensors\n",
            "model-00027-model.layers.10.self_attn.v_proj.weight.safetensors\n",
            "model-00028-model.layers.11.input_layernorm.weight.safetensors\n",
            "model-00029-model.layers.11.mlp.down_proj.weight.safetensors\n",
            "model-00030-model.layers.11.mlp.gate_proj.weight.safetensors\n",
            "model-00031-model.layers.11.mlp.up_proj.weight.safetensors\n",
            "model-00032-model.layers.11.post_attention_layernorm.weight.safetensors\n",
            "model-00033-model.layers.11.self_attn.k_proj.weight.safetensors\n",
            "model-00034-model.layers.11.self_attn.o_proj.weight.safetensors\n",
            "model-00035-model.layers.11.self_attn.q_proj.weight.safetensors\n",
            "model-00036-model.layers.11.self_attn.v_proj.weight.safetensors\n",
            "model-00037-model.layers.12.input_layernorm.weight.safetensors\n",
            "model-00038-model.layers.12.mlp.down_proj.weight.safetensors\n",
            "model-00039-model.layers.12.mlp.gate_proj.weight.safetensors\n",
            "model-00040-model.layers.12.mlp.up_proj.weight.safetensors\n",
            "model-00041-model.layers.12.post_attention_layernorm.weight.safetensors\n",
            "model-00042-model.layers.12.self_attn.k_proj.weight.safetensors\n",
            "model-00043-model.layers.12.self_attn.o_proj.weight.safetensors\n",
            "model-00044-model.layers.12.self_attn.q_proj.weight.safetensors\n",
            "model-00045-model.layers.12.self_attn.v_proj.weight.safetensors\n",
            "model.safetensors.index.json\n",
            "special_tokens_map.json\n",
            "tokenizer_config.json\n",
            "tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bv1jfIF9fYmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9c9d226f3ed4e0bbca5d7ffda272729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a96ba9ccc7fc4df2822edf29f97dfd93",
              "IPY_MODEL_783d758e587f4173b481b579556a0d79",
              "IPY_MODEL_48e04f100d204c3fa63cef6dab102532"
            ],
            "layout": "IPY_MODEL_db501b731109441d845adf617becaa94"
          }
        },
        "a96ba9ccc7fc4df2822edf29f97dfd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a48dfe02a494fc68b6e464f51e61f1a",
            "placeholder": "​",
            "style": "IPY_MODEL_c4a789ee7b14460499baf8d05678a04e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "783d758e587f4173b481b579556a0d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b363ad02b7c40269083155076d7e5d5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8be81f1627734ba987721d7d67358a2d",
            "value": 2
          }
        },
        "48e04f100d204c3fa63cef6dab102532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54f054e1b07467d9883527ba8df001e",
            "placeholder": "​",
            "style": "IPY_MODEL_7aa527e235014890b499f3de805d0b2d",
            "value": " 2/2 [00:02&lt;00:00,  1.21s/it]"
          }
        },
        "db501b731109441d845adf617becaa94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a48dfe02a494fc68b6e464f51e61f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4a789ee7b14460499baf8d05678a04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b363ad02b7c40269083155076d7e5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be81f1627734ba987721d7d67358a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c54f054e1b07467d9883527ba8df001e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa527e235014890b499f3de805d0b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a7c7de2df6d4b3989959df3bb28bd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_772b5681ad5e41768e0d56e73a80601f",
              "IPY_MODEL_513a1cbd9a7d4e3c86885551bd1804d0",
              "IPY_MODEL_7bda8351e581495eb40780bed08b52b0"
            ],
            "layout": "IPY_MODEL_4d873a3824ab429c9b9260577d251415"
          }
        },
        "772b5681ad5e41768e0d56e73a80601f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5c30b7533a54f7c9f9100edeb3fde15",
            "placeholder": "​",
            "style": "IPY_MODEL_b48e37b7297d4972853ff4d66b56e728",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "513a1cbd9a7d4e3c86885551bd1804d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cfbc7df60724c1ca1f61ea3dab7dc9e",
            "max": 254,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d4365f6bc9a4e6da1f424e7e637941b",
            "value": 254
          }
        },
        "7bda8351e581495eb40780bed08b52b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf319736bff481a9cbe4eea8b571ba2",
            "placeholder": "​",
            "style": "IPY_MODEL_4693169dea3d4a1898215c11c87fe1a8",
            "value": " 254/254 [01:26&lt;00:00,  2.98it/s]"
          }
        },
        "4d873a3824ab429c9b9260577d251415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c30b7533a54f7c9f9100edeb3fde15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b48e37b7297d4972853ff4d66b56e728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cfbc7df60724c1ca1f61ea3dab7dc9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4365f6bc9a4e6da1f424e7e637941b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bf319736bff481a9cbe4eea8b571ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4693169dea3d4a1898215c11c87fe1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}